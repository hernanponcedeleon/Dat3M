function @__llvm_atomic8_load exists only in right module
function @__llvm_atomic8_store exists only in right module
function @__llvm_atomic8_cmpxchg exists only in right module
function @__llvm_atomic8_rmw exists only in right module
function @__llvm_atomic16_load exists only in right module
function @__llvm_atomic16_store exists only in right module
function @__llvm_atomic16_cmpxchg exists only in right module
function @__llvm_atomic16_rmw exists only in right module
function @__llvm_atomic32_load exists only in right module
function @__llvm_atomic32_store exists only in right module
function @__llvm_atomic32_cmpxchg exists only in right module
function @__llvm_atomic32_rmw exists only in right module
function @__llvm_atomic64_load exists only in right module
function @__llvm_atomic64_store exists only in right module
function @__llvm_atomic64_cmpxchg exists only in right module
function @__llvm_atomic64_rmw exists only in right module
function @__llvm_atomic_fence exists only in right module
in function check_atomic_8:
  in block %0 / %0:
    >   %1 = call i8 @__llvm_atomic8_load(i8* @x1, i32 5)
    >   %2 = call i8 @__llvm_atomic8_rmw(i8* @y1, i8 %1, i32 2, i32 0)
    >   %3 = call { i8, i1 } @__llvm_atomic8_cmpxchg(i8* @x1, i8 %1, i8 %2, i32 5, i32 5)
    >   %4 = extractvalue { i8, i1 } %3, 1
    >   call void @__llvm_atomic8_store(i8* @x1, i8 %2, i32 0)
    >   %5 = zext i1 %4 to i32
    >   ret i32 %5
    <   %1 = load atomic i8, i8* @x1 seq_cst, align 1
    <   %2 = atomicrmw xchg i8* @y1, i8 %1 acquire, align 1
    <   %3 = cmpxchg i8* @x1, i8 %1, i8 %2 seq_cst seq_cst, align 1
    <   %4 = extractvalue { i8, i1 } %3, 1
    <   store atomic i8 %2, i8* @x1 monotonic, align 1
    <   %5 = zext i1 %4 to i32
    <   ret i32 %5

in function check_atomic_16:
  in block %0 / %0:
    >   %1 = call i16 @__llvm_atomic16_load(i16* @x2, i32 5)
    >   %2 = call i16 @__llvm_atomic16_rmw(i16* @y2, i16 %1, i32 2, i32 0)
    >   %3 = call { i16, i1 } @__llvm_atomic16_cmpxchg(i16* @x2, i16 %1, i16 %2, i32 5, i32 5)
    >   %4 = extractvalue { i16, i1 } %3, 1
    >   call void @__llvm_atomic16_store(i16* @x2, i16 %2, i32 0)
    >   %5 = zext i1 %4 to i32
    >   ret i32 %5
    <   %1 = load atomic i16, i16* @x2 seq_cst, align 2
    <   %2 = atomicrmw xchg i16* @y2, i16 %1 acquire, align 2
    <   %3 = cmpxchg i16* @x2, i16 %1, i16 %2 seq_cst seq_cst, align 2
    <   %4 = extractvalue { i16, i1 } %3, 1
    <   store atomic i16 %2, i16* @x2 monotonic, align 2
    <   %5 = zext i1 %4 to i32
    <   ret i32 %5

in function check_atomic_32:
  in block %0 / %0:
    >   %1 = call i32 @__llvm_atomic32_load(i32* @x4, i32 5)
    >   %2 = call i32 @__llvm_atomic32_rmw(i32* @y4, i32 %1, i32 2, i32 0)
    >   %3 = call { i32, i1 } @__llvm_atomic32_cmpxchg(i32* @x4, i32 %1, i32 %2, i32 5, i32 5)
    >   %4 = extractvalue { i32, i1 } %3, 1
    >   call void @__llvm_atomic32_store(i32* @x4, i32 %2, i32 0)
    >   %5 = zext i1 %4 to i32
    >   ret i32 %5
    <   %1 = load atomic i32, i32* @x4 seq_cst, align 4
    <   %2 = atomicrmw xchg i32* @y4, i32 %1 acquire, align 4
    <   %3 = cmpxchg i32* @x4, i32 %1, i32 %2 seq_cst seq_cst, align 4
    <   %4 = extractvalue { i32, i1 } %3, 1
    <   store atomic i32 %2, i32* @x4 monotonic, align 4
    <   %5 = zext i1 %4 to i32
    <   ret i32 %5

in function check_atomic_64:
  in block %0 / %0:
    >   %1 = call i64 @__llvm_atomic64_load(i64* @x8, i32 5)
    >   %2 = call i64 @__llvm_atomic64_rmw(i64* @y8, i64 %1, i32 2, i32 0)
    >   %3 = call { i64, i1 } @__llvm_atomic64_cmpxchg(i64* @x8, i64 %1, i64 %2, i32 5, i32 5)
    >   %4 = extractvalue { i64, i1 } %3, 1
    >   call void @__llvm_atomic64_store(i64* @x8, i64 %2, i32 0)
    >   %5 = zext i1 %4 to i32
    >   ret i32 %5
    <   %1 = load atomic i64, i64* @x8 seq_cst, align 8
    <   %2 = atomicrmw xchg i64* @y8, i64 %1 acquire, align 8
    <   %3 = cmpxchg i64* @x8, i64 %1, i64 %2 seq_cst seq_cst, align 8
    <   %4 = extractvalue { i64, i1 } %3, 1
    <   store atomic i64 %2, i64* @x8 monotonic, align 8
    <   %5 = zext i1 %4 to i32
    <   ret i32 %5

in function check_fence:
  in block %0 / %0:
    >   call void @__llvm_atomic_fence(i32 3)
    <   fence release

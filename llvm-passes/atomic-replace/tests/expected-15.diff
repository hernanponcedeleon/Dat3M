function @__llvm_atomic8_load exists only in right module
function @__llvm_atomic8_store exists only in right module
function @__llvm_atomic8_cmpxchg exists only in right module
function @__llvm_atomic8_rmw exists only in right module
function @__llvm_atomic16_load exists only in right module
function @__llvm_atomic16_store exists only in right module
function @__llvm_atomic16_cmpxchg exists only in right module
function @__llvm_atomic16_rmw exists only in right module
function @__llvm_atomic32_load exists only in right module
function @__llvm_atomic32_store exists only in right module
function @__llvm_atomic32_cmpxchg exists only in right module
function @__llvm_atomic32_rmw exists only in right module
function @__llvm_atomic64_load exists only in right module
function @__llvm_atomic64_store exists only in right module
function @__llvm_atomic64_cmpxchg exists only in right module
function @__llvm_atomic64_rmw exists only in right module
function @__llvm_atomic_fence exists only in right module
in function check_atomic_8:
  in block %0 / %0:
    >   %1 = call i8 @__llvm_atomic8_load(ptr @x1, i32 5)
    >   %2 = call i8 @__llvm_atomic8_rmw(ptr @y1, i8 %1, i32 2, i32 0)
    >   %3 = call { i8, i1 } @__llvm_atomic8_cmpxchg(ptr @x1, i8 %1, i8 %2, i32 5, i32 5)
    >   %4 = extractvalue { i8, i1 } %3, 1
    >   call void @__llvm_atomic8_store(ptr @x1, i8 %2, i32 0)
    >   %5 = zext i1 %4 to i32
    >   ret i32 %5
    <   %1 = load atomic i8, ptr @x1 seq_cst, align 1
    <   %2 = atomicrmw xchg ptr @y1, i8 %1 acquire, align 1
    <   %3 = cmpxchg ptr @x1, i8 %1, i8 %2 seq_cst seq_cst, align 1
    <   %4 = extractvalue { i8, i1 } %3, 1
    <   store atomic i8 %2, ptr @x1 monotonic, align 1
    <   %5 = zext i1 %4 to i32
    <   ret i32 %5

in function check_atomic_16:
  in block %0 / %0:
    >   %1 = call i16 @__llvm_atomic16_load(ptr @x2, i32 5)
    >   %2 = call i16 @__llvm_atomic16_rmw(ptr @y2, i16 %1, i32 2, i32 0)
    >   %3 = call { i16, i1 } @__llvm_atomic16_cmpxchg(ptr @x2, i16 %1, i16 %2, i32 5, i32 5)
    >   %4 = extractvalue { i16, i1 } %3, 1
    >   call void @__llvm_atomic16_store(ptr @x2, i16 %2, i32 0)
    >   %5 = zext i1 %4 to i32
    >   ret i32 %5
    <   %1 = load atomic i16, ptr @x2 seq_cst, align 2
    <   %2 = atomicrmw xchg ptr @y2, i16 %1 acquire, align 2
    <   %3 = cmpxchg ptr @x2, i16 %1, i16 %2 seq_cst seq_cst, align 2
    <   %4 = extractvalue { i16, i1 } %3, 1
    <   store atomic i16 %2, ptr @x2 monotonic, align 2
    <   %5 = zext i1 %4 to i32
    <   ret i32 %5

in function check_atomic_32:
  in block %0 / %0:
    >   %1 = call i32 @__llvm_atomic32_load(ptr @x4, i32 5)
    >   %2 = call i32 @__llvm_atomic32_rmw(ptr @y4, i32 %1, i32 2, i32 0)
    >   %3 = call { i32, i1 } @__llvm_atomic32_cmpxchg(ptr @x4, i32 %1, i32 %2, i32 5, i32 5)
    >   %4 = extractvalue { i32, i1 } %3, 1
    >   call void @__llvm_atomic32_store(ptr @x4, i32 %2, i32 0)
    >   %5 = zext i1 %4 to i32
    >   ret i32 %5
    <   %1 = load atomic i32, ptr @x4 seq_cst, align 4
    <   %2 = atomicrmw xchg ptr @y4, i32 %1 acquire, align 4
    <   %3 = cmpxchg ptr @x4, i32 %1, i32 %2 seq_cst seq_cst, align 4
    <   %4 = extractvalue { i32, i1 } %3, 1
    <   store atomic i32 %2, ptr @x4 monotonic, align 4
    <   %5 = zext i1 %4 to i32
    <   ret i32 %5

in function check_atomic_64:
  in block %0 / %0:
    >   %1 = call i64 @__llvm_atomic64_load(ptr @x8, i32 5)
    >   %2 = call i64 @__llvm_atomic64_rmw(ptr @y8, i64 %1, i32 2, i32 0)
    >   %3 = call { i64, i1 } @__llvm_atomic64_cmpxchg(ptr @x8, i64 %1, i64 %2, i32 5, i32 5)
    >   %4 = extractvalue { i64, i1 } %3, 1
    >   call void @__llvm_atomic64_store(ptr @x8, i64 %2, i32 0)
    >   %5 = zext i1 %4 to i32
    >   ret i32 %5
    <   %1 = load atomic i64, ptr @x8 seq_cst, align 8
    <   %2 = atomicrmw xchg ptr @y8, i64 %1 acquire, align 8
    <   %3 = cmpxchg ptr @x8, i64 %1, i64 %2 seq_cst seq_cst, align 8
    <   %4 = extractvalue { i64, i1 } %3, 1
    <   store atomic i64 %2, ptr @x8 monotonic, align 8
    <   %5 = zext i1 %4 to i32
    <   ret i32 %5

in function check_fence:
  in block %0 / %0:
    >   call void @__llvm_atomic_fence(i32 3)
    <   fence release
